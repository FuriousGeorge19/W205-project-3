{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joe Mirza - Project 3 - W205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>  \n",
    "### **My project has the following files:**  \n",
    "**1. Project_3_Joe_Mirza_w205.ipynb:** This notebook. To narrate the pipeline steps and perform a few presto queries once the data is landed in hadoop.   <br>  \n",
    "**2. ab.sh:** A bash script I run from within a while loop that runs on the command line and streams events into the pipeline using apache bench.   <br>  \n",
    "**3. game_api.py:** Takes the events from the last step and routes them from flask into kafka. Maps those incoming events into event dictionaries, appends header information and packages each bundle into a json before sending the object into kafka.    <br>  \n",
    "**4. stream_and_hive.py:** Reads the event objects from kafka. Uses pyspark to filter the 4 events types I'm supporting (default, purchase_sword, purchase_armor and join_a_guild) into 4 separate tables which are registered in hive and written to hadoop.     <br>  \n",
    "**5. docker-compose.yml:** Spins up the cluster, maps/coordinates the interaction between some of the services. Will pull a few pieces out of that file into this one inline in this notebook to demonstrate I understand how they work.   <br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will spin up the cluster with:        `     docker-compose up -d`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Services spun up:**\n",
    "- zookeeper\n",
    "- kafka\n",
    "- cloudera\n",
    "- spark\n",
    "- presto\n",
    "- mids\n",
    "<br>  \n",
    "The only new service here, relative to what we've done in Project 1 and 2, is presto. Spark is used in this project to filter, transform and ultimately write events to hadoop. We'll use presto in this notebook to perform sql queries.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Start up kafkacat to 'consume' or receive events from apache bench:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `docker-compose exec mids kafkacat -C -b kafka:29092 -t events -o beginning`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I followed the approach laid out in unit 13a, which didn't create the topic 'events' first but rather relied on the fact that kafkacat will create a topic 'events' if it doesn't already exist. But that requires entering the above command twice. Seems odd, but it works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the above command and the .yml, kafka is listening on port 29092\n",
    "    ```\n",
    "      kafka:\n",
    "        image: confluentinc/cp-kafka:latest\n",
    "        depends_on:\n",
    "          - zookeeper\n",
    "        environment:\n",
    "          KAFKA_BROKER_ID: 1\n",
    "          KAFKA_ZOOKEEPER_CONNECT: zookeeper:32181\n",
    "          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092\n",
    "          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n",
    "        expose:\n",
    "          - \"9092\"\n",
    "          - \"29092\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Before running flask, we'll discuss what game_api.py does and how I modified it. I'll only show the methods and flask decorators I created or modified so you don't have to wade through the whole thing. If you need to see all of game_api.py, it's in the repository.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.flask is imported to read and, well, 'route' the apache bench messages it receives  <br>    \n",
    "2.KafkaProducer is imported to send the events that are transformed here into the kafka queue   <br>  \n",
    "3.request is imported to append header information to the transformed events    <br>  \n",
    "4.Each of the 4 events type I'm supporting has a different flask decorator and associated python method. The one I created is join_a_guild. When flask's @app.route 'sees' an incoming event from apache bench ending in \"/join_a_guild\", it creates a join_guiild_event dictionary and sends it to the log_to_kakfa method. There the header is appended and the whole thing is sent to the `events` topic as a json by kafka producer. <br>  \n",
    "5.Sword purchases and Guild joins have metadata associated with each of them. In the case of sword purchases, it's the type of sword (e.g. broadsword, longsword or scimitar) and with guilds it's brewers, masons and assassins. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ```\n",
    "    import json\n",
    "    from kafka import KafkaProducer\n",
    "    from flask import Flask, request\n",
    "\n",
    "    app = Flask(__name__)\n",
    "    producer = KafkaProducer(bootstrap_servers='kafka:29092')\n",
    "\n",
    "    @app.route(\"/purchase_a_sword/<sword_name>\")\n",
    "    def purchase_a_sword(sword_name):\n",
    "        purchase_sword_event = {'event_type': 'purchase_sword', 'sword_type': sword_name}\n",
    "        log_to_kafka('events', purchase_sword_event)\n",
    "        return \"Sword Purchased!\\n\"\n",
    "\n",
    "    @app.route(\"/join_a_guild/<guild_name>\")\n",
    "    def join_a_guild(guild_name):\n",
    "        join_guild_event = {'event_type': 'join_a_guild','guild_type': guild_name}\n",
    "        log_to_kafka('events', join_guild_event)\n",
    "        return \"Guild Joined!\\n\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Let's run flask now**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `docker-compose exec mids env FLASK_APP=/w205/project-3-FuriousGeorge19/game_api.py flask run --host 0.0.0.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **With flask and kafka running, now is a good point to test whether what we've built up until this point is working by using apache bench to stream some events and see if they're picked up by flask and kafka **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than use the while loop in the live session slides, that had the apache bench calls in them, I thought I'd try to use the while loop to run the bash script ab.sh repeatedly instead, which I modified to have the types of events I needed to pass. I was pleasantly surprised when it worked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modified loop sends lots and lots (90 events) each time the loop runs. \n",
    "\n",
    "    ```\n",
    "    \n",
    "    while true; do \n",
    "      ./ab.sh; \n",
    "      sleep 10;  \n",
    "    done\n",
    "    \n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **It works. In the terminal window where flask is running we see lines like this:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ```\n",
    "    \n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:01] \"GET / HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:01] \"GET / HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:01] \"GET / HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:01] \"GET / HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:01] \"GET / HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:01] \"GET / HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:01] \"GET / HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:01] \"GET / HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:01] \"GET / HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:01] \"GET / HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:02] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:02] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:02] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:02] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:02] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "    127.0.0.1 - - [05/Dec/2020 08:57:02] \"GET /purchase_a_sword HTTP/1.0\" 200 -\n",
    "    \n",
    "    ```\n",
    "These are the raw events from apache bench."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **It works. In the window running flask we see lines like this:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"2.5\">\n",
    "\n",
    "{\"Host\": \"user1.comcast.com\", \"sword_type\": \"broadsword\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"} <br>   \n",
    "{\"Host\": \"user1.comcast.com\", \"sword_type\": \"broadsword\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"}   <br>   \n",
    "{\"Accept\": \"*/*\", \"Host\": \"user2.att.com\", \"event_type\": \"join_a_guild\", \"guild_type\": \"brewers\", \"User-Agent\": \"ApacheBench/2.3\"} <br>   \n",
    "{\"Accept\": \"*/*\", \"Host\": \"user2.att.com\", \"event_type\": \"join_a_guild\", \"guild_type\": \"brewers\", \"User-Agent\": \"ApacheBench/2.3\"} <br>   \n",
    "{\"Host\": \"user1.comcast.com\", \"sword_type\": \"longsword\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"} <br>   \n",
    "{\"Host\": \"user1.comcast.com\", \"sword_type\": \"longsword\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"} <br>   \n",
    "{\"Host\": \"user1.comcast.com\", \"sword_type\": \"longsword\", \"event_type\": \"purchase_sword\", \"Accept\": \"*/*\", \"User-Agent\": \"ApacheBench/2.3\"} <br>   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **With data flowing into kafka, we can now run stream_and_hive.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This: \n",
    "#### 1. Reads the event objects from kafka.\n",
    "#### 2. Uses pyspark to filter the 4 events types I'm supporting (default, purchase_sword, purchase_armor and join_a_guild) into 4 separate tables. I created the join_a_guild schema and modified purchase_sword's to support the metadata I mentioned earlier.\n",
    "#### 3. Registers those tables in hive and writes them to to hadoop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rather then describe the entire file, I'll show examples of some of the changes I made. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the schema I created joining a guild. It has an additional metadata field to support the type of guild: mason, assassins and brewers. \n",
    "\n",
    "\n",
    "    ```\n",
    "    def join_a_guild_event_schema():\n",
    "        \"\"\"\n",
    "        root\n",
    "        |-- Accept: string (nullable = true)\n",
    "        |-- Host: string (nullable = true)\n",
    "        |-- User-Agent: string (nullable = true)\n",
    "        |-- event_type: string (nullable = true)\n",
    "        |-- guild_type: string (nullable = true) \n",
    "        \"\"\"\n",
    "        return StructType([\n",
    "            StructField(\"Accept\", StringType(), True),\n",
    "            StructField(\"Host\", StringType(), True),\n",
    "            StructField(\"User-Agent\", StringType(), True),\n",
    "            StructField(\"event_type\", StringType(), True),\n",
    "            StructField(\"guild_type\", StringType(), True),\n",
    "        ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A user-defined function needs to be created to test whether or not an event is of type 'join_a_guild'.\n",
    "\n",
    "    ```\n",
    "    @udf('boolean')\n",
    "    def is_join_guild(event_as_json):\n",
    "        \"\"\"udf for filtering events\n",
    "        \"\"\"\n",
    "        event = json.loads(event_as_json)\n",
    "        if event['event_type'] == 'join_a_guild':\n",
    "            return True\n",
    "        return False\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Fields from the join_guilds table are written to hadoop \n",
    "   \n",
    "    ```\n",
    "    spark.sql(\"drop table if exists join_guilds\")\n",
    "        sql_string_guilds = \"\"\"\n",
    "            create external table if not exists join_guilds (\n",
    "                raw_event string,\n",
    "                timestamp string,\n",
    "                Accept string,\n",
    "                Host string,\n",
    "                `User-Agent` string,\n",
    "                event_type string,\n",
    "                guild_type string\n",
    "                )\n",
    "                stored as parquet\n",
    "                location '/tmp/join_guilds'\n",
    "                tblproperties (\"parquet.compress\"=\"SNAPPY\")\n",
    "                \"\"\"\n",
    "        spark.sql(sql_string_guilds)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### So we'll use this command to submit stream_and_hive.py to the spark container...\n",
    "\n",
    "#### `docker-compose exec spark spark-submit /w205/project-3-FuriousGeorge19/stream_and_hive.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And then use this command to start up presto and write some queries on the data we worked so hard to create\n",
    "\n",
    "#### `docker-compose exec presto presto --server presto:8080 --catalog hive --schema default`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We'll look at the tables we have in presto\n",
    "\n",
    "#### `presto:default> show tables;`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our results:\n",
    "   \n",
    "    ```\n",
    "    presto:default> show tables;\n",
    "           Table       \n",
    "    -------------------\n",
    "     armor_purchases   \n",
    "     default_purchases \n",
    "     join_guilds       \n",
    "     sword_purchases   \n",
    "    (4 rows)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We'll start by focusing on the table join_guilds. We created it from scratch and want to make sure the events and metadata were passed correctly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### This is a good start. event_type and guild_type are where they should be. \n",
    "\n",
    "\n",
    "```\n",
    "    presto:default> describe join_guilds;\n",
    "       Column   |  Type   | Comment \n",
    "    ------------+---------+---------\n",
    "     raw_event  | varchar |         \n",
    "     timestamp  | varchar |         \n",
    "     accept     | varchar |         \n",
    "     host       | varchar |         \n",
    "     user-agent | varchar |         \n",
    "     event_type | varchar |         \n",
    "     guild_type | varchar |  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## We'll select the most interesting columns from the table and look at the first 25 rows. This looks good. The event_type is parsed correctly and the metadata 'guild_type' is populated the way I expected it to be. \n",
    "\n",
    "```\n",
    "\n",
    "presto:default> select timestamp, host, \"user-agent\", event_type, guild_type from join_guilds limit 25;\n",
    "        timestamp        |     host      |   user-agent    |  event_type  | guild_type \n",
    "-------------------------+---------------+-----------------+--------------+------------\n",
    " 2020-12-06 10:51:18.293 | user2.att.com | ApacheBench/2.3 | join_a_guild | brewers    \n",
    " 2020-12-06 10:51:18.299 | user2.att.com | ApacheBench/2.3 | join_a_guild | brewers    \n",
    " 2020-12-06 10:51:18.305 | user2.att.com | ApacheBench/2.3 | join_a_guild | brewers    \n",
    " 2020-12-06 10:51:18.311 | user2.att.com | ApacheBench/2.3 | join_a_guild | brewers    \n",
    " 2020-12-06 10:51:18.317 | user2.att.com | ApacheBench/2.3 | join_a_guild | brewers    \n",
    " 2020-12-06 10:51:18.324 | user2.att.com | ApacheBench/2.3 | join_a_guild | brewers    \n",
    " 2020-12-06 10:51:18.332 | user2.att.com | ApacheBench/2.3 | join_a_guild | brewers    \n",
    " 2020-12-06 10:51:18.337 | user2.att.com | ApacheBench/2.3 | join_a_guild | brewers    \n",
    " 2020-12-06 10:51:18.347 | user2.att.com | ApacheBench/2.3 | join_a_guild | brewers    \n",
    " 2020-12-06 10:51:18.353 | user2.att.com | ApacheBench/2.3 | join_a_guild | brewers    \n",
    " 2020-12-06 10:51:19.028 | user2.att.com | ApacheBench/2.3 | join_a_guild | masons     \n",
    " 2020-12-06 10:51:19.037 | user2.att.com | ApacheBench/2.3 | join_a_guild | masons     \n",
    " 2020-12-06 10:51:19.048 | user2.att.com | ApacheBench/2.3 | join_a_guild | masons     \n",
    " 2020-12-06 10:51:19.057 | user2.att.com | ApacheBench/2.3 | join_a_guild | masons     \n",
    " 2020-12-06 10:51:19.068 | user2.att.com | ApacheBench/2.3 | join_a_guild | masons     \n",
    " 2020-12-06 10:51:19.076 | user2.att.com | ApacheBench/2.3 | join_a_guild | masons     \n",
    " 2020-12-06 10:51:19.082 | user2.att.com | ApacheBench/2.3 | join_a_guild | masons     \n",
    " 2020-12-06 10:51:19.087 | user2.att.com | ApacheBench/2.3 | join_a_guild | masons     \n",
    " 2020-12-06 10:51:19.095 | user2.att.com | ApacheBench/2.3 | join_a_guild | masons     \n",
    " 2020-12-06 10:51:19.1   | user2.att.com | ApacheBench/2.3 | join_a_guild | masons     \n",
    " 2020-12-06 10:51:19.737 | user2.att.com | ApacheBench/2.3 | join_a_guild | assassins  \n",
    " 2020-12-06 10:51:19.743 | user2.att.com | ApacheBench/2.3 | join_a_guild | assassins  \n",
    " 2020-12-06 10:51:19.748 | user2.att.com | ApacheBench/2.3 | join_a_guild | assassins  \n",
    " 2020-12-06 10:51:19.754 | user2.att.com | ApacheBench/2.3 | join_a_guild | assassins  \n",
    " 2020-12-06 10:51:19.759 | user2.att.com | ApacheBench/2.3 | join_a_guild | assassins  \n",
    "(25 rows)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We'll count the number of users that joined a guild (so far)\n",
    "```\n",
    "presto:default> select count(event_type) \n",
    "             -> from join_guilds;\n",
    " _col0 \n",
    "-------\n",
    "  1590 \n",
    "(1 row)\n",
    "\n",
    "```\n",
    "#### 1,590 users joined a guild of any type\n",
    "\n",
    "### ...and the number that joined the brewers guild\n",
    "\n",
    "```\n",
    "presto:default> select count(guild_type) from join_guilds where guild_type ='masons';\n",
    " _col0 \n",
    "-------\n",
    "   710 \n",
    "(1 row)\n",
    "```\n",
    "#### 710 users joined the masons' guild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We'll switch to looking to the sword_purchases table, the other table whose schema I modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## We'll take a look at a subset of the interesting columns from the sword_purchases table. event_type 'purchase_sword' and the associated metadata 'sword_type' look like they've been passed and parsed correctly. \n",
    "```\n",
    "\n",
    "presto:default> select timestamp, host, \"user-agent\", event_type, sword_type from sword_purchases limit 25;\n",
    "        timestamp        |       host        |   user-agent    |   event_type   | sword_type \n",
    "-------------------------+-------------------+-----------------+----------------+------------\n",
    " 2020-12-06 10:56:58.271 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | broadsword \n",
    " 2020-12-06 10:56:58.277 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | broadsword \n",
    " 2020-12-06 10:56:58.282 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | broadsword \n",
    " 2020-12-06 10:56:58.286 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | broadsword \n",
    " 2020-12-06 10:56:58.292 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | broadsword \n",
    " 2020-12-06 10:56:58.298 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | broadsword \n",
    " 2020-12-06 10:56:58.303 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | broadsword \n",
    " 2020-12-06 10:56:58.308 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | broadsword \n",
    " 2020-12-06 10:56:58.315 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | broadsword \n",
    " 2020-12-06 10:56:58.32  | user1.comcast.com | ApacheBench/2.3 | purchase_sword | broadsword \n",
    " 2020-12-06 10:56:58.939 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | longsword  \n",
    " 2020-12-06 10:56:58.955 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | longsword  \n",
    " 2020-12-06 10:56:58.96  | user1.comcast.com | ApacheBench/2.3 | purchase_sword | longsword  \n",
    " 2020-12-06 10:56:58.966 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | longsword  \n",
    " 2020-12-06 10:56:58.975 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | longsword  \n",
    " 2020-12-06 10:56:58.981 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | longsword  \n",
    " 2020-12-06 10:56:58.987 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | longsword  \n",
    " 2020-12-06 10:56:58.993 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | longsword  \n",
    " 2020-12-06 10:56:58.997 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | longsword  \n",
    " 2020-12-06 10:56:59.002 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | longsword  \n",
    " 2020-12-06 10:56:59.712 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | scimitar   \n",
    " 2020-12-06 10:56:59.717 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | scimitar   \n",
    " 2020-12-06 10:56:59.722 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | scimitar   \n",
    " 2020-12-06 10:56:59.726 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | scimitar   \n",
    " 2020-12-06 10:56:59.731 | user1.comcast.com | ApacheBench/2.3 | purchase_sword | scimitar   \n",
    "(25 rows)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ## We'll see how many swords have been purchased....\n",
    "```\n",
    "\n",
    "presto:default> select count(event_type) from sword_purchases;\n",
    " _col0 \n",
    "-------\n",
    "  3060 \n",
    "(1 row)\n",
    "\n",
    "```\n",
    "#### There have been 3,060 sword purchases so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ## ...and how many of those swords were scimitars...\n",
    "```\n",
    "\n",
    "presto:default> select count(sword_type) from sword_purchases where sword_type = 'scimitar';\n",
    " _col0 \n",
    "-------\n",
    "  1130 \n",
    "(1 row\n",
    "\n",
    "```\n",
    "#### There have been 1,130 scimitars purchased so far. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
